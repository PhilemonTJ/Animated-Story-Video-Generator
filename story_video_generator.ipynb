{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f9b258",
   "metadata": {},
   "source": [
    "# Animated Story Video Generator\n",
    "\n",
    "This notebook generates an animated story video using Google Generative AI for both images and narration. Each scene is created based on a user-provided theme, with AI-generated visuals and audio, and then assembled into a video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19e10e0",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages\n",
    "Install all necessary Python packages. This cell only needs to be run once per environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f887f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-genai google-generativeai moviepy Pillow nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d390d4e0",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "Import all required libraries for data processing, image and audio handling, and video creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ded95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import display, HTML\n",
    "from moviepy.editor import ImageClip, AudioFileClip, CompositeVideoClip, concatenate_videoclips\n",
    "import time\n",
    "from base64 import b64encode\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "import contextlib\n",
    "import wave\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65055c01",
   "metadata": {},
   "source": [
    "## 3. Set Up Google API Key\n",
    "Set your Google API key as an environment variable. Replace `'YOUR_GOOGLE_API_KEY'` with your actual key or use a secure method to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a3a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_API_KEY'] = 'YOUR_GOOGLE_API_KEY'  # TODO: Replace with your actual API key or use a secure method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0f4f8",
   "metadata": {},
   "source": [
    "## 4. Initialize Google Generative AI Client\n",
    "Set up the client and model IDs for text and image generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(http_options={'api_version': 'v1alpha'})\n",
    "MODEL = \"models/gemini-2.0-flash-exp\"\n",
    "IMAGE_MODEL_ID = \"imagen-3.0-generate-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a96ca8",
   "metadata": {},
   "source": [
    "## 5. Define Story Generation Function\n",
    "This function generates a sequence of story scenes, each with an image prompt, narration, and character description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35696811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def generate_story_sequence(complete_story: str, pages: int) -> Tuple[List[Dict], int]:\n",
    "    \"\"\"\n",
    "    Generate a story sequence using Google Generative AI.\n",
    "    Returns a list of scene dictionaries and the number of pages.\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=f'''you are an animation video producer. Generate a story sequence about {complete_story} in {pages} scenes (with interactions and characters), 1 sec each scene. Write:\\n\\nimage_prompt:(define art style for kids animation(consistent for all the characters)) a full description of the scene, the characters in it, and the background in 20 words or less. Progressively shift the scene as the story advances.\\naudio_text: a one-sentence dialogue/narration for the scene.\\ncharacter_description: no people ever, only animals and objects. Describe all characters (consistent names, features, clothing, etc.) with an art style reference (e.g., \"Pixar style,\" \"photorealistic,\" \"Ghibli\", \"Anime,\" \"Digital Art,\" \"Comic Book,\" \"Disney style,\") in 30 words or less.''',\n",
    "        config={\n",
    "            'response_mime_type': 'application/json',\n",
    "            'response_schema': list\n",
    "        }\n",
    "    )\n",
    "    try:\n",
    "        story_data_list = json.loads(response.text)\n",
    "        if isinstance(story_data_list, list) and len(story_data_list) > 0:\n",
    "            story_data = story_data_list[0]\n",
    "            return story_data.get('complete_story', []), story_data.get('pages', pages)\n",
    "        else:\n",
    "            return [], pages\n",
    "    except (KeyError, TypeError, IndexError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error in parsing the story data : {e}\")\n",
    "        return [], pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac7b23",
   "metadata": {},
   "source": [
    "## 6. Generate Story Segments\n",
    "Set your story theme and number of scenes, then generate the story sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5093861",
   "metadata": {},
   "outputs": [],
   "source": [
    "theme = \"Jerry steals a giant cheese, and Tom goes on a wild chase across a bustling city.\"\n",
    "num_scenes = 10\n",
    "\n",
    "story_segments, _ = generate_story_sequence(theme, num_scenes)\n",
    "print(json.dumps(story_segments, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601102b",
   "metadata": {},
   "source": [
    "## 7. Helper Functions for Audio Generation\n",
    "Define a context manager for writing WAV files and a function to generate audio narration for each scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb98d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def wave_file(filename, channels=1, rate=24000, sample_width=2):\n",
    "    with wave.open(filename, \"wb\") as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(sample_width)\n",
    "        wf.setframerate(rate)\n",
    "        yield wf\n",
    "\n",
    "def generate_audio_live(api_text, output_filename):\n",
    "    \"\"\"\n",
    "    Generate audio narration for a given text using Google Generative AI Live API.\n",
    "    \"\"\"\n",
    "    import asyncio\n",
    "    collected_audio = bytearray()\n",
    "\n",
    "    async def _generate():\n",
    "        config = {\n",
    "            \"response_modalities\": [\"AUDIO\"]\n",
    "        }\n",
    "        async with client.aio.live.connect(model=MODEL, config=config) as session:\n",
    "            await session.send(input=api_text, end_of_turn=True)\n",
    "            async for response in session.receive():\n",
    "                if response.data:\n",
    "                    collected_audio.extend(response.data)\n",
    "        return bytes(collected_audio)\n",
    "\n",
    "    audio_bytes = asyncio.run(_generate())\n",
    "    with wave_file(output_filename) as wf:\n",
    "        wf.writeframes(audio_bytes)\n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7a162",
   "metadata": {},
   "source": [
    "## 8. Generate Images, Audio, and Assemble Video\n",
    "For each scene, generate an image and audio, then assemble them into a video clip. All clips are concatenated into the final video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b38492",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_audio_files = []  # Track temporary audio files\n",
    "temp_image_files = []  # Track temporary image files\n",
    "video_clips = []       # Store video clips for each scene\n",
    "\n",
    "audio_negative_prompt = \"don't say OK , I will do this or that, just only read this story using voice expressions without introductions or ending ,more segments are coming ,don't say OK , I will do this or that:\\n\"\n",
    "\n",
    "for i, segment in enumerate(story_segments):\n",
    "    image_prompt = segment['image_prompt']\n",
    "    audio_text = audio_negative_prompt + segment['audio_text']\n",
    "    char_desc = segment['character_description']\n",
    "    print(f\"Processing scene {i+1}:\")\n",
    "    print(\"Image Prompt:\", image_prompt)\n",
    "    print(\"Audio Text:\", segment['audio_text'])\n",
    "    print(\"Character Description:\", char_desc)\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    # Generate image using Google Imagen\n",
    "    combined_prompt = \"detailed children book animation style \" + image_prompt + \" \" + char_desc\n",
    "    result = client.models.generate_images(\n",
    "        model=IMAGE_MODEL_ID,\n",
    "        prompt=combined_prompt,\n",
    "        config={\n",
    "            \"number_of_images\": 1,\n",
    "            \"output_mime_type\": \"image/jpeg\",\n",
    "            \"person_generation\": \"DONT_ALLOW\",\n",
    "            \"aspect_ratio\": \"1:1\"\n",
    "        }\n",
    "    )\n",
    "    try:\n",
    "        if not result.generated_images:\n",
    "            raise ValueError(\"No images were generated. The prompt might have been flagged as harmful. Please modify your prompt and try again.\")\n",
    "        for generated_image in result.generated_images:\n",
    "            image = Image.open(BytesIO(generated_image.image.image_bytes))\n",
    "    except Exception as e:\n",
    "        print(\"Image generation failed \", e)\n",
    "        continue\n",
    "    image_path = f\"image_{i}.png\"\n",
    "    image.save(image_path)\n",
    "    temp_image_files.append(image_path)\n",
    "    display(image)\n",
    "\n",
    "    # Generate audio narration\n",
    "    audio_path = f\"audio_{i}.wav\"\n",
    "    audio_path = generate_audio_live(audio_text, audio_path)\n",
    "    temp_audio_files.append(audio_path)\n",
    "\n",
    "    # Create video clip (image + audio)\n",
    "    audio_clip = AudioFileClip(audio_path)\n",
    "    np_image = np.array(image)\n",
    "    image_clip = ImageClip(np_image).set_duration(audio_clip.duration)\n",
    "    composite_clip = CompositeVideoClip([image_clip]).set_audio(audio_clip)\n",
    "    video_clips.append(composite_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d986719b",
   "metadata": {},
   "source": [
    "## 9. Concatenate and Display Final Video\n",
    "Combine all video clips into a single video, display it in the notebook, and clean up temporary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299cd0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_video = concatenate_videoclips(video_clips)\n",
    "output_filename = f\"{int(time.time())}_output_video.mp4\"\n",
    "print(\"Writing final video to\", output_filename)\n",
    "final_video.write_videofile(output_filename, fps=24)\n",
    "\n",
    "def show_video(video_path):\n",
    "    \"\"\"Display video in notebook\"\"\"\n",
    "    video_file = open(video_path, \"rb\")\n",
    "    video_bytes = video_file.read()\n",
    "    video_b64 = b64encode(video_bytes).decode()\n",
    "    video_tag = f'<video width=\"640\" height=\"480\" controls><source src=\"data:video/mp4;base64,{video_b64}\" type=\"video/mp4\"></video>'\n",
    "    return HTML(video_tag)\n",
    "\n",
    "display(show_video(output_filename))\n",
    "\n",
    "# Cleanup: Close video clips and remove temporary files\n",
    "final_video.close()\n",
    "for clip in video_clips:\n",
    "    clip.close()\n",
    "for file in temp_audio_files:\n",
    "    os.remove(file)\n",
    "for file in temp_image_files:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da796dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**A video player will appear above after successful execution.**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
